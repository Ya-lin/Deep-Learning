{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882ed68-f063-44b9-bf45-645eec858876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pdb import set_trace\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from dataset import get_data\n",
    "from network import AE\n",
    "from training import trainer\n",
    "from testing import reconstruction, display\n",
    "\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eef208-382c-4673-b82d-f9d373134006",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(dataset=\"fmnist\")\n",
    "args.device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args.img = 32       # image size\n",
    "args.ch = 1         # num of channel\n",
    "args.batch = 100    # batch size\n",
    "args.dim = 2        # embedding dimension\n",
    "args.epoch = 10\n",
    "args.lr = 1e-3\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b1a5e-abda-43d9-b781-7931e30e7623",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_data(args.dataset, args.batch)\n",
    "len(loader.train), len(loader.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45341b-84c9-4a96-9c59-d8024810057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader.train))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6647d-8365-4fc8-98f6-f6202a7f62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE(args.img, args.ch, args.dim).to(args.device)\n",
    "print(\"\\n\", model.shape_bf)\n",
    "print(\"\\n\", model.encoder.summary())\n",
    "print(\"\\n\", model.decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4ddff-e74d-4a30-8985-7a706395f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE(args.img, args.ch, args.dim).to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c2774-ba85-47be-91f3-e64a58cf7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = trainer(model, loader, args.epoch, \n",
    "                         optimizer, loss_fn, args.device)\n",
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2c6ac-d29c-4935-b224-a1072e500015",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.train, label=\"train loss\")\n",
    "plt.plot(history.test, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59271cca-e57b-4dbf-af54-b89be1cf6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "checkpoint = torch.load(\"best_model.pth\", weights_only=True)\n",
    "model.load_state_dict(checkpoint[\"model_dict\"])\n",
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fad6d-833a-44cb-a97d-aafdcc8627f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_hat, Y = reconstruction(model, loader.test, 50, args.device)\n",
    "X.shape, X_hat.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe445e-cbe7-491c-a76d-bc7c3256d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Example real clothing items\")\n",
    "display(X)\n",
    "print(\"Correpsonding reconstructions\")\n",
    "display(X_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761f7d4-e9f2-462f-8cb3-07ee546a08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the example images\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encoder(X).cpu().numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5084729-1a6a-4d2f-8155-7875f9421a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour the embeddings by their label (clothing type - see table)\n",
    "figsize = 8\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], \n",
    "            cmap=\"rainbow\", c=Y, alpha=0.8, s=3)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843c2f0-de77-4c48-8040-97b0c90a371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the range of the existing embeddings\n",
    "mins, maxs = np.min(embeddings, axis=0), np.max(embeddings, axis=0)\n",
    "\n",
    "# Sample some points in the latent space\n",
    "grid_width, grid_height = (6, 3)\n",
    "sample = np.random.uniform(mins, maxs, size=(grid_width*grid_height,args.dim))\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccee94e-0f0d-4e0a-9c47-e2e87f3c5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the sampled points\n",
    "with torch.no_grad():\n",
    "    generated_sample = model.decoder(sample).cpu().numpy()\n",
    "generated_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc551ef-12d8-4887-a4e0-35217c6a98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a plot\n",
    "figsize = 8\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "\n",
    "# ... the original embeddings ...\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=\"black\", alpha=0.5, s=2)\n",
    "\n",
    "# ... and the newly generated points in the latent space\n",
    "plt.scatter(sample[:, 0], sample[:, 1], c=\"#00B0F0\", alpha=1, s=40)\n",
    "plt.show()\n",
    "\n",
    "# Add underneath a grid of the decoded images\n",
    "fig = plt.figure(figsize=(figsize, grid_height * 2))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(grid_width * grid_height):\n",
    "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(0.5, -0.35, str(np.round(sample[i, :], 1)),\n",
    "            fontsize=10, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.imshow(generated_sample[i, :, :].squeeze(), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa0dbb-645c-4f06-8d4a-a478e4c7c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour the embeddings by their label (clothing type - see table)\n",
    "figsize = 12\n",
    "grid_size = 15\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], cmap=\"rainbow\",\n",
    "            c=Y, alpha=0.8, s=300)\n",
    "plt.colorbar()\n",
    "\n",
    "x = np.linspace(min(embeddings[:, 0]), max(embeddings[:, 0]), grid_size)\n",
    "y = np.linspace(max(embeddings[:, 1]), min(embeddings[:, 1]), grid_size)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xv = xv.flatten()\n",
    "yv = yv.flatten()\n",
    "grid = np.array(list(zip(xv, yv)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_sample = model.decoder(grid).cpu().numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(figsize, figsize))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(grid_size**2):\n",
    "    ax = fig.add_subplot(grid_size, grid_size, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(generated_sample[i, :, :].squeeze(), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347350f-084a-43f1-b2af-7c6302921ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
